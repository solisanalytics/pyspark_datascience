{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "799a0da1-ad29-4c69-8ecd-e2829b09fd82",
   "metadata": {},
   "source": [
    "# Harnessing the Power of Python with Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6162a-e288-4c8c-b04b-373c444e930b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d84b9a-2a08-4c90-be0f-3ddf7b4ba29c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import collect_list\n",
    "from itertools import combinations\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6ea60-ade4-42ca-9f8b-89dcae1f1597",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44961269-8078-4df2-9803-3bb093516800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize spark session\n",
    "spark = (SparkSession.builder.appName('OnlineRetailAnalysis')\n",
    "         .getOrCreate())\n",
    "\n",
    "# file path\n",
    "file_path = 'online_retail_II_2010-2011.csv'\n",
    "\n",
    "# read dataset\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# display dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd35d70-9614-4814-94f8-2d03d7a1e093",
   "metadata": {},
   "source": [
    "### Market Basket Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40488b6-9fb8-44ec-9f63-d89abd5f409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter columns and remove nulls\n",
    "df_filtered = df.select('Invoice', 'StockCode').na.drop()\n",
    "\n",
    "# group by invoice and aggregate stockcodes\n",
    "df_grouped = df_filtered.groupBy('Invoice').agg(collect_list('StockCode').alias('Items'))\n",
    "\n",
    "# generate and count item pairs\n",
    "item_pairs = (df_grouped.rdd.flatMap(lambda row: combinations(row[1], 2))\n",
    "                                     .map(lambda pair: (pair, 1)))\n",
    "\n",
    "pair_frequencies = item_pairs.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# sort pairs by frequency\n",
    "sorted_pairs = pair_frequencies.sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "# display top 10 pairs\n",
    "sorted_pairs.take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkenv:Python",
   "language": "python",
   "name": "conda-env-sparkenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
